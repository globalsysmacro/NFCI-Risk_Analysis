{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this analysis is to infer market bottoms from Chicago Financial Conditions sub index-risk. \n",
    "The National Financial Conditions Index (NFCI) and adjusted NFCI (ANFCI) are each constructed to have an average value of zero and a standard deviation of one over a sample period extending back to 1971. Positive values of the NFCI have been historically associated with tighter-than-average financial conditions, while negative values have been historically associated with looser-than-average financial conditions.\n",
    "Analysis looks for the dates when NFCI Risk sub index signals tighter-than-average financial conditions compared to previous weeks consecutively i.e. 4 weeks in a row\n",
    "NFCI Risk sub index includes Financial indicators that are informative on money markets, short term risk on/off sentiments and more importantly it does not include US equity markets. This is important for avoiding endonegeity. The same analysis can be carried out with NFCI Credit sub index \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix \n",
    "from scipy.stats import f_oneway, ttest_ind\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "from IPython.display import display\n",
    "import random; random.seed(0)\n",
    "import string\n",
    "import os\n",
    "import pandas_datareader.data as web\n",
    "from pandas.tseries.offsets import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path='/Users/aybarsatalay/Desktop/Python'\n",
    "os.chdir(path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2009-09-11', '2010-05-07', '2010-11-19', '2011-06-10',\n",
      "               '2012-05-04', '2013-06-07', '2014-09-19', '2014-12-26',\n",
      "               '2015-08-21', '2015-12-18', '2018-02-02'],\n",
      "              dtype='datetime64[ns]', name='DATE', freq=None)\n"
     ]
    }
   ],
   "source": [
    "start='2009-08-08'\n",
    "end='2018-02-15'\n",
    "df=(web.DataReader('NFCIRISK','fred',start,end))\n",
    "df['daily_return']=df.NFCIRISK.pct_change()\n",
    "df['neg_returns'] = df.daily_return.lt(0)\n",
    "df['succesive_downs']=df['neg_returns'].groupby((df['neg_returns']!=df['neg_returns'].shift()).cumsum()).cumsum()\n",
    "trigger_dates=(df[df['succesive_downs']==4.0].index)\n",
    "print(trigger_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get historical data for SPY\n",
    "\n",
    "spy = pd.read_csv('SPY.csv',index_col=['Date'],parse_dates=True)[['Adj Close']]\n",
    "spy=pd.DataFrame(spy,index=spy.index)\n",
    "spy['returns']=spy['Adj Close'].pct_change()\n",
    "del spy['Adj Close']\n",
    "spy=spy.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_Days    -0.011768\n",
      "2_Days    -0.012616\n",
      "3_Days    -0.007475\n",
      "5_Days    -0.011049\n",
      "10_Days   -0.023222\n",
      "21_Days   -0.023482\n",
      "Name: _avg_returns_given_lookahead_, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# In order to quantify if identifying trigger dates produces meaningful results, \n",
    "#I've calculated the subsequent cumulative return over N number of days following each instance of the consecutive tightining\n",
    "#I then calculated the average cumulative return for each N day look ahead period\n",
    "# The lookahead periods I chose were 1, 2, 3, 5, 10, and 21 days. \n",
    "#As can ben seen from the results, there is a clear pattern: Current average cumulative returns are negative across all look ahead period and magnitute of this negativity increases with the range of lookahead\n",
    "\n",
    "def _cumlrets_given_trigger(trigger_dates, look):\n",
    "    '''function to calculate conditional cumulative returns given trigger dates and lookahead period'''\n",
    "    cr = {}\n",
    "    for date in trigger_dates:\n",
    "        start_int = spy.index.get_loc(date)\n",
    "        start = spy.index[start_int]\n",
    "        end = start + look * BDay()\n",
    "        cumlrets = spy.ix[start:end].cumsum().iloc[-1]\n",
    "        cr[date] = cumlrets.returns \n",
    "    conditional_rets = pd.Series(cr, index=cr.keys(), \\\n",
    "                                 name='_{} days lookahead_'.format(look)).sort_index()\n",
    "    return conditional_rets\n",
    "\n",
    "def _get_avgrets_bylook(trigger_dates):\n",
    "    '''function to aggregate conditional cumulative returns given trigger dates and lookahead period'''\n",
    "    lookahead = [1, 2, 3, 5, 10, 21]\n",
    "    rets_dict = {}\n",
    "    avg_returns_looks = {} \n",
    "    for look in lookahead:\n",
    "        rets = _cumlrets_given_trigger(trigger_dates, look)\n",
    "        mean_rets = rets.mean()\n",
    "        avg_returns_looks['{}_Days'.format(look)] = mean_rets\n",
    "        rets_dict['{}_Days'.format(look)] = rets\n",
    "    #print(rets_dict)\n",
    "\n",
    "    avg_rets_looks = pd.Series(avg_returns_looks, index=avg_returns_looks.keys(),\\\n",
    "                               name='_avg_returns_given_lookahead_')\n",
    "    avg_rets_looks = avg_rets_looks[['{}_Days'.format(str(i)) for i in lookahead]]\n",
    "    return avg_rets_looks, rets_dict   \n",
    "    \n",
    "\"\"\"looking at the average\"\"\"\n",
    "avg_crets, avgdict = _get_avgrets_bylook(trigger_dates)\n",
    "print (avg_crets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            _1 days lookahead_  _2 days lookahead_  _3 days lookahead_  \\\n",
      "2009-09-11            0.004677            0.008856            0.023991   \n",
      "2010-05-07            0.029166            0.026325            0.040311   \n",
      "2010-11-19            0.001919           -0.012557            0.002217   \n",
      "2011-06-10           -0.013127           -0.000441           -0.018226   \n",
      "2012-05-04           -0.015428           -0.019440           -0.025371   \n",
      "2013-06-07            0.012721            0.002405           -0.005872   \n",
      "2014-09-19           -0.008623           -0.014347           -0.006520   \n",
      "2014-12-26            0.004568           -0.000798           -0.010721   \n",
      "2015-08-21           -0.072157           -0.084397           -0.044606   \n",
      "2015-12-18           -0.009568           -0.000494            0.011890   \n",
      "2018-02-02           -0.063592           -0.043890           -0.049315   \n",
      "\n",
      "            _5 days lookahead_  _10 days lookahead_  _21 days lookahead_  \n",
      "2009-09-11            0.023137             0.001767             0.032988  \n",
      "2010-05-07            0.009775            -0.032155            -0.063973  \n",
      "2010-11-19           -0.009431             0.024746             0.043873  \n",
      "2011-06-10           -0.013037            -0.014732             0.025712  \n",
      "2012-05-04           -0.026323            -0.070340            -0.082403  \n",
      "2013-06-07            0.003064            -0.016694             0.013816  \n",
      "2014-09-19           -0.014710            -0.021549            -0.052898  \n",
      "2014-12-26           -0.011256            -0.016542            -0.010361  \n",
      "2015-08-21           -0.021192            -0.054365            -0.028671  \n",
      "2015-12-18            0.010239             0.001535            -0.079267  \n",
      "2018-02-02           -0.071802            -0.057118            -0.057118  \n"
     ]
    }
   ],
   "source": [
    "#To show distribution (not just averages) below function depicts all trigger dates with selected look ahead periods \n",
    "def create_df(trigger_dates):\n",
    "    lookahead = [1, 2, 3, 5, 10, 21]\n",
    "    df=pd.DataFrame()\n",
    "    for look in lookahead:\n",
    "        rets = _cumlrets_given_trigger(trigger_dates, look)\n",
    "        #print(rets)\n",
    "        df=df.append(rets,ignore_index=False)\n",
    "    \n",
    "    return (df.T)\n",
    "df= create_df(trigger_dates)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
